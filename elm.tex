\documentclass{article}
\usepackage[hidelinks]{hyperref}
%\usepackage{helvetica} % uses helvetica postscript font (download helvetica.sty)
%\usepackage{newcent}   % uses new century schoolbook postscript font 
%\setlength{\textwidth}{5.5in} % set width of text portion

\usepackage{polski}
%\usepackage[polish, english]{babel}
%\usepackage[T1]{fontenc} % T1, OT4
\usepackage[utf8]{inputenc}
\usepackage{indentfirst}
\usepackage{float}



\title{Projekt aplikacji do ekstremalnego uczenia maszynowego do klasyfikacji big data}
\author{Abdelkarim Ahmed, Hernik Aleksandra}
\date{}
\begin{document}

\clearpage
\vspace*{\fill}
\begin{center}
\begin{minipage}{.9\textwidth}
\maketitle
\end{minipage}
\end{center}
\vfill % equivalent to \vspace{\fill}
\clearpage

\tableofcontents

\section*{Wprowadzenie}
\addcontentsline{toc}{section}{Wprowadzenie}
\section*{Wykaz ważniejszych oznaczeń i akronimów}
\begin{itemize}
\item ELM -- Extreme Learning Machine, czyli 
\item SLFN -- Single-Layer Feed-forward Network 
\item Big Data
\item Toolbox
\end{itemize}
\addcontentsline{toc}{section}{Wykaz ważniejszych oznaczeń i akronimów}
\section{Opracowanie modelu pracy sieci do ekstremalnego uczenia maszynowego ELM}
\subsection{Rys historyczny}
W 2004 roku Guang-Bin Huang, Qin-Yu Zhu i Chee-Kheong Siew zaproponowali koncepcję ELM w pracy \textit{Extreme Learning Machine: A New Learning Scheme of Feedforward Neural Networks}, dotyczącej SLFN. W tym samym roku Guang-Bin Huang i Chee-Kheong Siew zaproponowali również w artykule \textit{Extreme Learning Machine: RBF Network Case} wariant ELM dotyczący sieci radialnych, których nie dotyczy ta praca. Od tego czasu pojawiło się wiele innych prac dotyczących tego zagadnienia, a zagadnienie stało się popularnym tematem. \par
Z wyżej wymienionymi pracami związane są kontrowersje dotyczące rzeczywistej innowacyjności rozwiązania Huanga i innych, a także oskarżenia dotyczące plagiatowania i nieuwzględniania w bibliografii rzeczywistych głównych źródeł pracy -- według nich artykuł dotyczący SLFN opiera się głównie na pracy \textit{Feed Forward Neural Networks With Random Weights} Woutera Schmidta, Martina Kraaijvelda i Roberta Duina z 1992, a artykuł dotyczący sieci radialnych wzoruje się na \textit{Multivariable Functional Interpolation and Adaptive Networks} Davida Broomheada i Davida Lowe'a. Huang wskazał pewne różnice między tymi pracami.
\subsection{Założenia dla sieci neuronowych klasy ELM}
\subsection{Wnioski i uwagi}
\section{Wykonanie implementacji ELM w Pythonie i Matlabie}
\subsection{Projekt aplikacji sieci ELM w Pythonie}
\subsection{Projekt aplikacji sieci ELM w Matlabie}
\subsection{Wnioski i uwagi}
\section{Trening ELM dla wybranych benchmarków big data i small data}
\subsection{Opis wybranych benchmarków}
\subsection{Trening dla instancji klasy small data}
\subsection{Trening dla instancji klasy big data}
\subsection{Wnioski i uwagi}
asdfasdfsad
\section{Eksperymenty obejmujące instancje klasyfikacji wraz z badaniem ich wydajności}
\section*{Podsumowanie}
\addcontentsline{toc}{section}{Podsumowanie}
\section*{Bibliografia}
\addcontentsline{toc}{section}{Bibliografia}
TODO dobre referencje
\begin{itemize}
\item A. Akusok, K.-M. Björk, Y. Miche, A. Lendasse \textit{High-Performance Extreme Learning Machines: A Complete Toolbox for Big Data Applications}
\item G.-B. Huang, L. Chen, C.-K. Siew, \textit{Extreme learning machine: Theory and applications} 
\item http://elmorigin.wixsite.com/originofelm
\end{itemize}
\section*{Wykaz rysunków}
\addcontentsline{toc}{section}{Wykaz rysunków}
\section*{Wykaz tabel}
\addcontentsline{toc}{section}{Wykaz tabel}
\section*{Dodatek. Instrukcja obsługi aplikacji}
\addcontentsline{toc}{section}{Dodatek. Instrukcja obsługi aplikacji}
\end{document}













