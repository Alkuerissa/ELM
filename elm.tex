\documentclass{article}
\usepackage[hidelinks]{hyperref}
%\usepackage{helvetica} % uses helvetica postscript font (download helvetica.sty)
%\usepackage{newcent}   % uses new century schoolbook postscript font 
%\setlength{\textwidth}{5.5in} % set width of text portion

\usepackage{polski}
%\usepackage[polish, english]{babel}
%\usepackage[T1]{fontenc} % T1, OT4
\usepackage[utf8]{inputenc}
\usepackage{indentfirst}
\usepackage{float}
\usepackage{enumitem}



\title{Projekt aplikacji do ekstremalnego uczenia maszynowego do klasyfikacji big data}
\author{Abdelkarim Ahmed, Hernik Aleksandra}
\date{}
\begin{document}

\clearpage
\vspace*{\fill}
\begin{center}
\begin{minipage}{.9\textwidth}
\maketitle
\end{minipage}
\end{center}
\vfill % equivalent to \vspace{\fill}
\clearpage

\tableofcontents
\clearpage

\section*{Wprowadzenie}
\addcontentsline{toc}{section}{Wprowadzenie}
Celem pracy jest przetestowanie ELM na wybranych zestawach small data, a następnie big data, przy użyciu służących do tego, istniejących już bibliotek do Pythona i Matlaba.

Ahmed Abdelkarim zajmował się porównywaniem wyników dla big data i small data przy użyciu Pythona.
Aleksandra Hernik sprawdzała dokładność i wydajność uczenia dla big data za pomocą Matlaba.
\clearpage
\section*{Wykaz ważniejszych oznaczeń i akronimów}
\addcontentsline{toc}{section}{Wykaz ważniejszych oznaczeń i akronimów}
\begin{itemize}[label={},leftmargin=*]
\item ELM -- Extreme Learning Machine
\item SLFN -- Single-Layer Feed-forward Network 
\item BP -- Back-propagation
\item MLP -- Multilayer Perceptron
\item SVM -- Support Vector Machines
\item Big Data
\item Toolbox
\end{itemize}
\clearpage
\section{Opracowanie modelu pracy sieci do ekstremalnego uczenia maszynowego ELM}
\subsection{Rys historyczny}
W 2004 roku Guang-Bin Huang, Qin-Yu Zhu i Chee-Kheong Siew zaproponowali koncepcję ELM w pracy \textit{Extreme Learning Machine: A New Learning Scheme of Feedforward Neural Networks}, dotyczącej SLFN. W tym samym roku Guang-Bin Huang i Chee-Kheong Siew zaproponowali również w artykule \textit{Extreme Learning Machine: RBF Network Case} wariant ELM dotyczący sieci radialnych, których nie dotyczy ta praca. Od tego czasu pojawiło się wiele innych prac dotyczących tego zagadnienia, a zagadnienie stało się popularnym tematem. \par
Z wyżej wymienionymi pracami związane są kontrowersje dotyczące rzeczywistej innowacyjności rozwiązania Huanga i innych, a także oskarżenia dotyczące plagiatowania i nieuwzględniania w bibliografii rzeczywistych głównych źródeł pracy -- według nich artykuł dotyczący SLFN opiera się głównie na pracy \textit{Feed Forward Neural Networks With Random Weights} Woutera Schmidta, Martina Kraaijvelda i Roberta Duina z 1992, a artykuł dotyczący sieci radialnych wzoruje się na \textit{Multivariable Functional Interpolation and Adaptive Networks} Davida Broomheada i Davida Lowe'a. Huang wskazał pewne różnice między tymi pracami.
\subsection{Założenia dla sieci neuronowych klasy ELM}
Sieci neuronowe klasy ELM opierają się na losowym generowaniu neuronów warstwy ukrytej bez późniejszego ich dostosowywania do danych -- dzięki temu, że wszystkie ich parametry mogą zostać dobrane losowo, są one niezależne od danych trenujących, a w przeciwieństwie do metody BP, wagi wyjściowe są niezależne od wag wejściowych, co pozwala na nieiteracyjne ich wyznaczenie. Takie rozwiązanie zapewnia znacznie szybszy czas działania od innych metod, takich jak BP, MLP i SVM.
\subsection{Wnioski i uwagi}
\clearpage
\section{Wykonanie implementacji ELM w Pythonie i Matlabie}
\subsection{Projekt aplikacji sieci ELM w Pythonie}
\subsection{Projekt aplikacji sieci ELM w Matlabie}
\subsection{Wnioski i uwagi}
\clearpage
\section{Trening ELM dla wybranych benchmarków big data i small data}
\subsection{Opis wybranych benchmarków}
\subsection{Trening dla instancji klasy small data}
\subsection{Trening dla instancji klasy big data}
\subsection{Wnioski i uwagi}
\clearpage
\section{Eksperymenty obejmujące instancje klasyfikacji wraz z badaniem ich wydajności}
\clearpage
\section*{Podsumowanie}
\addcontentsline{toc}{section}{Podsumowanie}

\clearpage
\section*{Bibliografia}
\addcontentsline{toc}{section}{Bibliografia}
TODO dobre referencje
\begin{itemize}
\item A. Akusok, K.-M. Björk, Y. Miche, A. Lendasse \textit{High-Performance Extreme Learning Machines: A Complete Toolbox for Big Data Applications}
\item G.-B. Huang, L. Chen, C.-K. Siew, \textit{Extreme learning machine: Theory and applications} 
\item http://elmorigin.wixsite.com/originofelm
\end{itemize}
\clearpage
\section*{Wykaz rysunków}
\addcontentsline{toc}{section}{Wykaz rysunków}

\clearpage
\section*{Wykaz tabel}
\addcontentsline{toc}{section}{Wykaz tabel}

\clearpage
\section*{Dodatek. Instrukcja obsługi aplikacji}
\addcontentsline{toc}{section}{Dodatek. Instrukcja obsługi aplikacji}

\clearpage
\end{document}













